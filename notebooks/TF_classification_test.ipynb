{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os ,sys \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV,train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "#     model = keras.Sequential([\n",
    "#   layers.Dense(128, activation=tf.nn.relu, input_shape=[X_train.shape[1]] , kernel_initializer= tf.keras.initializers.lecun_normal()   ),\n",
    "#   #layers.DenseFeatures(feature_columns=feature_columns),\n",
    "#   layers.Dense(units=128, activation=tf.nn.relu),\n",
    "# #   layers.Dropout(rate=0.2),\n",
    "#   layers.Dense(units=128, activation=tf.nn.relu),\n",
    "#   layers.Dense(1, activation='sigmoid')\n",
    "#   ])\n",
    "    model = keras.Sequential ( [\n",
    "        layers.Dense(128, input_shape=[X_train.shape[1]], activation='relu'),\n",
    "                               layers.Dense(128, activation='relu'),\n",
    "                               layers.Dense(2, activation='sigmoid')\n",
    "    ] )\n",
    " \n",
    "    #optimizer = tf.keras.optimizers.RMSprop(0.0001)\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=0.001)\n",
    "\n",
    "#     model.compile(loss='mean_squared_error',\n",
    "#                 optimizer=optimizer,\n",
    "#                 metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "    model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "#                   loss = 'binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "# MAE: 0.3804038200959926\n",
    "# MSE: 0.2931826937166191\n",
    "# Accuracy = 71.81%.\n",
    "# R^2: -0.010843632592412389\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(32, input_shape=(8,), activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(2, activation='softmax'))\n",
    "# model.compile(Adam(lr=0.05),\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    \n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Abs Error [MPG]')\n",
    "    plt.plot(hist['epoch'], hist['mean_absolute_error'],\n",
    "           label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_mean_absolute_error'],\n",
    "           label = 'Val Error')\n",
    "    plt.ylim([0,5])\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Square Error [$MPG^2$]')\n",
    "    plt.plot(hist['epoch'], hist['mean_squared_error'],\n",
    "           label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_mean_squared_error'],\n",
    "           label = 'Val Error')\n",
    "    plt.ylim([0,20])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"SubCh2_TrainingData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(\"Sample_Names\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Asexual.stage..hpi.</th>\n",
       "      <th>PF3D7_0100100</th>\n",
       "      <th>PF3D7_0100200</th>\n",
       "      <th>PF3D7_0100300</th>\n",
       "      <th>PF3D7_0100600</th>\n",
       "      <th>PF3D7_0100800</th>\n",
       "      <th>PF3D7_0101300</th>\n",
       "      <th>PF3D7_0101600</th>\n",
       "      <th>PF3D7_0101800</th>\n",
       "      <th>PF3D7_0101900</th>\n",
       "      <th>...</th>\n",
       "      <th>PF3D7_1478600</th>\n",
       "      <th>PF3D7_1478800</th>\n",
       "      <th>PF3D7_1479000</th>\n",
       "      <th>PF3D7_1479200</th>\n",
       "      <th>PF3D7_1479400</th>\n",
       "      <th>PF3D7_1479500</th>\n",
       "      <th>PF3D7_1479600</th>\n",
       "      <th>PF3D7_1479900</th>\n",
       "      <th>PF3D7_1480000</th>\n",
       "      <th>PF3D7_1480100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1034.000000</td>\n",
       "      <td>1034.000000</td>\n",
       "      <td>1027.000000</td>\n",
       "      <td>1034.000000</td>\n",
       "      <td>883.000000</td>\n",
       "      <td>965.000000</td>\n",
       "      <td>995.000000</td>\n",
       "      <td>961.000000</td>\n",
       "      <td>955.000000</td>\n",
       "      <td>838.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1034.000000</td>\n",
       "      <td>1012.000000</td>\n",
       "      <td>1034.000000</td>\n",
       "      <td>995.000000</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>966.000000</td>\n",
       "      <td>1031.000000</td>\n",
       "      <td>967.000000</td>\n",
       "      <td>1031.000000</td>\n",
       "      <td>1004.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.839458</td>\n",
       "      <td>0.588485</td>\n",
       "      <td>-0.400360</td>\n",
       "      <td>-1.562115</td>\n",
       "      <td>-0.207137</td>\n",
       "      <td>0.430695</td>\n",
       "      <td>0.314014</td>\n",
       "      <td>0.387900</td>\n",
       "      <td>0.627587</td>\n",
       "      <td>-0.128795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107491</td>\n",
       "      <td>0.588307</td>\n",
       "      <td>1.606575</td>\n",
       "      <td>1.325516</td>\n",
       "      <td>0.016055</td>\n",
       "      <td>0.694918</td>\n",
       "      <td>-0.354395</td>\n",
       "      <td>0.842168</td>\n",
       "      <td>-0.844200</td>\n",
       "      <td>-0.729089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.296079</td>\n",
       "      <td>0.386959</td>\n",
       "      <td>0.550427</td>\n",
       "      <td>0.434017</td>\n",
       "      <td>0.801218</td>\n",
       "      <td>0.428597</td>\n",
       "      <td>0.541705</td>\n",
       "      <td>0.528767</td>\n",
       "      <td>0.545944</td>\n",
       "      <td>0.649186</td>\n",
       "      <td>...</td>\n",
       "      <td>1.172411</td>\n",
       "      <td>0.836556</td>\n",
       "      <td>1.028962</td>\n",
       "      <td>1.232031</td>\n",
       "      <td>0.844699</td>\n",
       "      <td>0.679436</td>\n",
       "      <td>0.749504</td>\n",
       "      <td>0.840444</td>\n",
       "      <td>0.425826</td>\n",
       "      <td>0.512802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>-0.626506</td>\n",
       "      <td>-1.662472</td>\n",
       "      <td>-3.074627</td>\n",
       "      <td>-3.356092</td>\n",
       "      <td>-2.080098</td>\n",
       "      <td>-2.230567</td>\n",
       "      <td>-2.081346</td>\n",
       "      <td>-1.378680</td>\n",
       "      <td>-3.017334</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.988117</td>\n",
       "      <td>-1.712406</td>\n",
       "      <td>-1.606718</td>\n",
       "      <td>-2.254148</td>\n",
       "      <td>-2.894438</td>\n",
       "      <td>-2.597529</td>\n",
       "      <td>-1.788443</td>\n",
       "      <td>-2.661921</td>\n",
       "      <td>-4.473189</td>\n",
       "      <td>-3.516266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.331500</td>\n",
       "      <td>-0.746014</td>\n",
       "      <td>-1.848422</td>\n",
       "      <td>-0.596077</td>\n",
       "      <td>0.177324</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>0.121013</td>\n",
       "      <td>0.299758</td>\n",
       "      <td>-0.421732</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.845809</td>\n",
       "      <td>-0.012059</td>\n",
       "      <td>0.875702</td>\n",
       "      <td>0.206936</td>\n",
       "      <td>-0.477323</td>\n",
       "      <td>0.315216</td>\n",
       "      <td>-0.857169</td>\n",
       "      <td>0.251184</td>\n",
       "      <td>-1.113803</td>\n",
       "      <td>-0.994019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.546455</td>\n",
       "      <td>-0.492601</td>\n",
       "      <td>-1.568791</td>\n",
       "      <td>-0.128347</td>\n",
       "      <td>0.407459</td>\n",
       "      <td>0.332069</td>\n",
       "      <td>0.335356</td>\n",
       "      <td>0.616210</td>\n",
       "      <td>-0.118397</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.171865</td>\n",
       "      <td>0.553314</td>\n",
       "      <td>1.783477</td>\n",
       "      <td>1.566865</td>\n",
       "      <td>0.095367</td>\n",
       "      <td>0.662110</td>\n",
       "      <td>-0.513296</td>\n",
       "      <td>0.778487</td>\n",
       "      <td>-0.873248</td>\n",
       "      <td>-0.770163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.815803</td>\n",
       "      <td>-0.170949</td>\n",
       "      <td>-1.270046</td>\n",
       "      <td>0.260402</td>\n",
       "      <td>0.653834</td>\n",
       "      <td>0.669431</td>\n",
       "      <td>0.567817</td>\n",
       "      <td>0.960965</td>\n",
       "      <td>0.198978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993174</td>\n",
       "      <td>1.212148</td>\n",
       "      <td>2.394341</td>\n",
       "      <td>2.339903</td>\n",
       "      <td>0.490433</td>\n",
       "      <td>1.106035</td>\n",
       "      <td>-0.019362</td>\n",
       "      <td>1.353813</td>\n",
       "      <td>-0.592636</td>\n",
       "      <td>-0.553993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>2.361282</td>\n",
       "      <td>3.214877</td>\n",
       "      <td>0.008173</td>\n",
       "      <td>3.026750</td>\n",
       "      <td>2.328200</td>\n",
       "      <td>2.609883</td>\n",
       "      <td>6.339745</td>\n",
       "      <td>3.597698</td>\n",
       "      <td>2.801731</td>\n",
       "      <td>...</td>\n",
       "      <td>3.360148</td>\n",
       "      <td>2.835897</td>\n",
       "      <td>4.675642</td>\n",
       "      <td>3.822690</td>\n",
       "      <td>3.329101</td>\n",
       "      <td>2.944060</td>\n",
       "      <td>3.323877</td>\n",
       "      <td>3.843143</td>\n",
       "      <td>1.410671</td>\n",
       "      <td>2.480246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 4953 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Asexual.stage..hpi.  PF3D7_0100100  PF3D7_0100200  PF3D7_0100300  \\\n",
       "count          1034.000000    1034.000000    1027.000000    1034.000000   \n",
       "mean              9.839458       0.588485      -0.400360      -1.562115   \n",
       "std               4.296079       0.386959       0.550427       0.434017   \n",
       "min               4.000000      -0.626506      -1.662472      -3.074627   \n",
       "25%               8.000000       0.331500      -0.746014      -1.848422   \n",
       "50%               8.000000       0.546455      -0.492601      -1.568791   \n",
       "75%              12.000000       0.815803      -0.170949      -1.270046   \n",
       "max              46.000000       2.361282       3.214877       0.008173   \n",
       "\n",
       "       PF3D7_0100600  PF3D7_0100800  PF3D7_0101300  PF3D7_0101600  \\\n",
       "count     883.000000     965.000000     995.000000     961.000000   \n",
       "mean       -0.207137       0.430695       0.314014       0.387900   \n",
       "std         0.801218       0.428597       0.541705       0.528767   \n",
       "min        -3.356092      -2.080098      -2.230567      -2.081346   \n",
       "25%        -0.596077       0.177324       0.001646       0.121013   \n",
       "50%        -0.128347       0.407459       0.332069       0.335356   \n",
       "75%         0.260402       0.653834       0.669431       0.567817   \n",
       "max         3.026750       2.328200       2.609883       6.339745   \n",
       "\n",
       "       PF3D7_0101800  PF3D7_0101900      ...        PF3D7_1478600  \\\n",
       "count     955.000000     838.000000      ...          1034.000000   \n",
       "mean        0.627587      -0.128795      ...             0.107491   \n",
       "std         0.545944       0.649186      ...             1.172411   \n",
       "min        -1.378680      -3.017334      ...            -1.988117   \n",
       "25%         0.299758      -0.421732      ...            -0.845809   \n",
       "50%         0.616210      -0.118397      ...            -0.171865   \n",
       "75%         0.960965       0.198978      ...             0.993174   \n",
       "max         3.597698       2.801731      ...             3.360148   \n",
       "\n",
       "       PF3D7_1478800  PF3D7_1479000  PF3D7_1479200  PF3D7_1479400  \\\n",
       "count    1012.000000    1034.000000     995.000000     830.000000   \n",
       "mean        0.588307       1.606575       1.325516       0.016055   \n",
       "std         0.836556       1.028962       1.232031       0.844699   \n",
       "min        -1.712406      -1.606718      -2.254148      -2.894438   \n",
       "25%        -0.012059       0.875702       0.206936      -0.477323   \n",
       "50%         0.553314       1.783477       1.566865       0.095367   \n",
       "75%         1.212148       2.394341       2.339903       0.490433   \n",
       "max         2.835897       4.675642       3.822690       3.329101   \n",
       "\n",
       "       PF3D7_1479500  PF3D7_1479600  PF3D7_1479900  PF3D7_1480000  \\\n",
       "count     966.000000    1031.000000     967.000000    1031.000000   \n",
       "mean        0.694918      -0.354395       0.842168      -0.844200   \n",
       "std         0.679436       0.749504       0.840444       0.425826   \n",
       "min        -2.597529      -1.788443      -2.661921      -4.473189   \n",
       "25%         0.315216      -0.857169       0.251184      -1.113803   \n",
       "50%         0.662110      -0.513296       0.778487      -0.873248   \n",
       "75%         1.106035      -0.019362       1.353813      -0.592636   \n",
       "max         2.944060       3.323877       3.843143       1.410671   \n",
       "\n",
       "       PF3D7_1480100  \n",
       "count    1004.000000  \n",
       "mean       -0.729089  \n",
       "std         0.512802  \n",
       "min        -3.516266  \n",
       "25%        -0.994019  \n",
       "50%        -0.770163  \n",
       "75%        -0.553993  \n",
       "max         2.480246  \n",
       "\n",
       "[8 rows x 4953 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country                 object\n",
       "Asexual.stage..hpi.      int64\n",
       "Kmeans.Grp              object\n",
       "PF3D7_0100100          float64\n",
       "PF3D7_0100200          float64\n",
       "PF3D7_0100300          float64\n",
       "PF3D7_0100600          float64\n",
       "PF3D7_0100800          float64\n",
       "PF3D7_0101300          float64\n",
       "PF3D7_0101600          float64\n",
       "PF3D7_0101800          float64\n",
       "PF3D7_0101900          float64\n",
       "PF3D7_0102000          float64\n",
       "PF3D7_0102100          float64\n",
       "PF3D7_0102200          float64\n",
       "PF3D7_0102300          float64\n",
       "PF3D7_0102400          float64\n",
       "PF3D7_0102500          float64\n",
       "PF3D7_0102600          float64\n",
       "PF3D7_0102700          float64\n",
       "PF3D7_0102800          float64\n",
       "PF3D7_0102900          float64\n",
       "PF3D7_0103100          float64\n",
       "PF3D7_0103200          float64\n",
       "PF3D7_0103300          float64\n",
       "PF3D7_0103400          float64\n",
       "PF3D7_0103500          float64\n",
       "PF3D7_0103600          float64\n",
       "PF3D7_0103700          float64\n",
       "PF3D7_0103800          float64\n",
       "                        ...   \n",
       "PF3D7_1476500          float64\n",
       "PF3D7_1476600          float64\n",
       "PF3D7_1476700          float64\n",
       "PF3D7_1476800          float64\n",
       "PF3D7_1476900          float64\n",
       "PF3D7_1477000          float64\n",
       "PF3D7_1477200          float64\n",
       "PF3D7_1477300          float64\n",
       "PF3D7_1477500          float64\n",
       "PF3D7_1477600          float64\n",
       "PF3D7_1477700          float64\n",
       "PF3D7_1477800          float64\n",
       "PF3D7_1477900          float64\n",
       "PF3D7_1478000          float64\n",
       "PF3D7_1478100          float64\n",
       "PF3D7_1478200          float64\n",
       "PF3D7_1478300          float64\n",
       "PF3D7_1478400          float64\n",
       "PF3D7_1478500          float64\n",
       "PF3D7_1478600          float64\n",
       "PF3D7_1478800          float64\n",
       "PF3D7_1479000          float64\n",
       "PF3D7_1479200          float64\n",
       "PF3D7_1479400          float64\n",
       "PF3D7_1479500          float64\n",
       "PF3D7_1479600          float64\n",
       "PF3D7_1479900          float64\n",
       "PF3D7_1480000          float64\n",
       "PF3D7_1480100          float64\n",
       "ClearanceRate           object\n",
       "Length: 4956, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict ={\"Fast\":1,\"Slow\":0  }\n",
    "\n",
    "df.dropna(subset=[\"ClearanceRate\"],inplace=True)\n",
    "X = df.drop([\"ClearanceRate\",\"Country\",\"Kmeans.Grp\"],axis=1)\n",
    "y = df[\"ClearanceRate\"].apply(lambda x:my_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in X.columns :\n",
    "    X[m].fillna((X[m].mean()),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resample , y_resample = rus.fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_resample)\n",
    "X_scaled = scaler.transform(X_resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.40301283,  0.82652678,  2.38906128, ...,  1.49930219,\n",
       "         1.79250597,  0.98279301],\n",
       "       [ 1.0372362 , -1.03482205,  0.32204322, ..., -1.1959874 ,\n",
       "        -0.46463718, -0.96421775],\n",
       "       [ 1.51731921,  0.23866515, -0.12072065, ..., -1.14869764,\n",
       "        -0.59841571, -0.25374113],\n",
       "       ...,\n",
       "       [-0.40301283,  0.49776048, -1.61005942, ..., -1.00160282,\n",
       "         0.10685684, -0.00804972],\n",
       "       [ 1.0372362 ,  0.51669258, -0.37639935, ...,  0.73190773,\n",
       "         0.325446  ,  3.34020704],\n",
       "       [-0.40301283, -0.31941335, -0.57081276, ..., -0.60322877,\n",
       "        -0.11088629, -0.19201407]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat = to_categorical(y_resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.5\n",
       "0    0.5\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_resample).value_counts() / len(y_resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_resample ,y_cat , test_size=0.33, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               634112    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 650,882\n",
      "Trainable params: 650,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The patience parameter is the amount of epochs to check for improvement\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "# Display training progress by printing a single dot for each completed epoch\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch % 10 == 0: \n",
    "            #print('')\n",
    "            print('.', end='')\n",
    "        if epoch % 100 == 0: \n",
    "            #print('')\n",
    "            print('*', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0803 12:51:42.632146 140735963005888 deprecation.py:323] From /Users/barradd/anaconda2/envs/ztdl/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 320 samples, validate on 80 samples\n",
      "Epoch 1/1000\n",
      ".*320/320 - 0s - loss: 0.6975 - accuracy: 0.4969 - val_loss: 0.6931 - val_accuracy: 0.4375\n",
      "Epoch 2/1000\n",
      "320/320 - 0s - loss: 5.4429 - accuracy: 0.5000 - val_loss: 6.6487 - val_accuracy: 0.5875\n",
      "Epoch 3/1000\n",
      "320/320 - 0s - loss: 7.9079 - accuracy: 0.5094 - val_loss: 6.6487 - val_accuracy: 0.5875\n",
      "Epoch 4/1000\n",
      "320/320 - 0s - loss: 7.9079 - accuracy: 0.5094 - val_loss: 6.6487 - val_accuracy: 0.5875\n",
      "Epoch 5/1000\n",
      "320/320 - 0s - loss: 7.9079 - accuracy: 0.5094 - val_loss: 6.6487 - val_accuracy: 0.5875\n",
      "Epoch 6/1000\n",
      "320/320 - 0s - loss: 7.9079 - accuracy: 0.5094 - val_loss: 6.6487 - val_accuracy: 0.5875\n",
      "Epoch 7/1000\n",
      "320/320 - 0s - loss: 7.9079 - accuracy: 0.5094 - val_loss: 6.6487 - val_accuracy: 0.5875\n",
      "Epoch 8/1000\n",
      "320/320 - 0s - loss: 7.9079 - accuracy: 0.5094 - val_loss: 6.6487 - val_accuracy: 0.5875\n",
      "Epoch 9/1000\n",
      "320/320 - 0s - loss: 7.9079 - accuracy: 0.5094 - val_loss: 6.6487 - val_accuracy: 0.5875\n",
      "Epoch 10/1000\n",
      "320/320 - 0s - loss: 7.9079 - accuracy: 0.5094 - val_loss: 6.6487 - val_accuracy: 0.5875\n",
      "Epoch 11/1000\n",
      ".320/320 - 0s - loss: 7.9079 - accuracy: 0.5094 - val_loss: 6.6487 - val_accuracy: 0.5875\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    epochs=1000,\n",
    "                    batch_size=2,\n",
    "                    use_multiprocessing=True,\n",
    "                    validation_split = 0.2, \n",
    "                    verbose=2, \n",
    "                    callbacks=[early_stop, PrintDot()]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score,classification_report, confusion_matrix,accuracy_score,matthews_corrcoef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
       "       1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
       "       1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
       "       1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
       "       1., 1., 0., 1., 0.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-752209a91761>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"MCC\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/ztdl/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict)\u001b[0m\n\u001b[1;32m   1850\u001b[0m     \"\"\"\n\u001b[1;32m   1851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1852\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m     \u001b[0mlabels_given\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/ztdl/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test.flatten(),y_pred.flatten()))\n",
    "print (\"Accuracy\")\n",
    "print (accuracy_score(y_test,y_pred))\n",
    "print (\"MCC\")\n",
    "print (accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
